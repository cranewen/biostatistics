---
title: "Final Exam"
author: "Yanhe Wen"
output:
  pdf_document: default
  html_notebook: default
---

##Question 1
###(a)
```{r}
y<-as.numeric(t(read.table(file = "DataPois.txt", header = TRUE)))
size_y <- length(y)
Ey <- mean(y)
cat("Sample size is:",size_y)
cat("sample mean is:",Ey)
```
###(b)
```{r warning=FALSE}
nloglik <- function(x) -sum(log2(dpois(y, lambda = exp(x))))
optim(par = 1, nloglik)$par
```
###(c)
```{r warning=FALSE}
nboot <- 1000
boot.data <- rep(NA, nboot)

for(i in 1:nboot){
  data.star <- y[sample(1:size_y,replace = TRUE)]
  nloglik1c <- function(x) -sum(log2(dpois(data.star, lambda = exp(x))))
  boot.data[i] <- optim(par = 1, nloglik1c)$par
}
t.test(boot.data, alternative = "two.sided", mu = 1, conf.level = 0.95)
```
The conclusion is the p-value is 2.2e-16, so the mean of $\theta$ is not equal to 1.

##Question 2
###(a)
```{r warning=FALSE}
library(ISLR)
ncidata <- NCI60$data
ncilabs <- NCI60$labs

a <- which(ncilabs %in% names(which(table(ncilabs)<3))) # an array with indexes which only 1 or 2 repeated
ncidata <- ncidata[-a,] # delete the data by adding - to the indexes
ncilabs <- ncilabs[-a]

```
###(b)
```{r warning=FALSE}
pairwise.t.test(ncidata[,1], ncilabs, p.adjust.method = "fdr")
cat("From the table, all the p-values are greater than 0.05, so there are no differences in groups ")

```
###(c)
```{r warning=FALSE}
shapiro.test(residuals(lm(ncidata[,1]~ncilabs)))
cat("p-value is 0.4414 proves the pairwise test is appropriate")
```
###(d)
```{r warning=FALSE}
p_values <- apply(ncidata, 2, function(x) anova(lm(x~ncilabs))[["Pr(>F)"]][1])
p_fdrs <- p.adjust(p_values, method = "fdr")
cat("There are",sum(p_fdrs < 0.05),"genes express differently.")
```

##Question 3
###(a)
```{r warning=FALSE}
pairs(state.x77)
cat("From the plot, Illiteracy and Murder variables have linear corraltion with it.")
```
###(b)
```{r warning=FALSE}
#Here the indexes represent life expectancy, income, illiteracy and frost respectively
statex77.data <- as.data.frame(state.x77)
lin.reg <- lm(statex77.data$`Life Exp`~statex77.data$Income+statex77.data$Illiteracy+statex77.data$Frost)
summary(lin.reg)
cat("y = 72 + 0.00018*Income - 1.56*Illiteracy - 0.006*Frost")
cat("Only illiteracy is significantly related to life expectancy.")
```
###(c)
```{r warning=FALSE}


```

##Question 4
###(a)
```{r warning=FALSE, message=FALSE}
library(ALL)
data(ALL)
ALLB <- ALL[, ALL$BT %in% c("B","B1","B2","B3","B4")]
```
###(b)
```{r warning=FALSE}
library("genefilter")
f_cv <- function(x) {(sd(x)/mean(x))>0.2 }
sel1 <- genefilter(exprs(ALLB), filterfun(f_cv))
sel_ALLB <- data.frame(ALLB)[,sel1]
cat(sum(sel1),"are selected.")

```
###(c)
We can use principle components analysis. Because pca is very critical to clustering. By eliminating 
unrelated elements, it forms the linear form which will be the best for clustering.

###(d)
I use ward method for hierarchical clustering.
```{r warning=FALSE}
hcluster.data <- sel_ALLB
hc.ward <- hclust(dist(hcluster.data, method = "euclidean"), method = "ward.D2")

table(cutree(hc.ward, k = 4), ALLB$mol.biol)
table(cutree(hc.ward, k = 4), ALLB$BT)
```

###(e)
```{r warning=FALSE}
library(gplots)
#heatmap for B stages
heatmap.2(as.matrix(sel_ALLB), 
          hclustfun = function(d) hclust(dist(d, method = "euclidean"), method = "ward.D2"),
          col=topo.colors(75))
#heatmap for bio names
sel_ALLB.biol <- sel_ALLB[, ALLB$mol.biol]
heatmap.2(as.matrix(sel_ALLB.biol), 
        hclustfun = function(d) hclust(dist(d, method = "euclidean"), method = "ward.D2"),
        col=topo.colors(75))
cat("I think biology types are better.")
```

###(f)
```{r warning=FALSE, message=FALSE}
library(limma)
library(plyr)

ALLB1234 <- ALL[, ALL$BT %in% c("B1","B2","B3","B4")]
ALLB1234.factor <- factor(ALLB1234$BT)
ALLB1234.factor <- revalue(ALLB1234.factor, c("B3"="B34","B4"="B34"))

design.ma <- model.matrix(~ 0 + ALLB1234.factor)
colnames(design.ma) <- c("B1","B2","B34")
fit1234 <- lmFit(ALLB1234, design.ma)
fit1234 <- eBayes(fit1234)
cont.ma <- makeContrasts(B1-B2,B2-B34, levels=ALLB1234.factor)
fit_f <- contrasts.fit(fit1234, cont.ma)
fit_f <- eBayes(fit_f)
p_values_f <- fit_f$F.p.value
p_fdrs_f <- p.adjust(p_values_f, method = "fdr")
cat("There are",sum(p_fdrs_f<0.05),"genes are selected.")
```

###(g)
```{r warning=FALSE,error=TRUE}
library(e1071)
sel_ALLB1234 <- ALLB1234[which(p_fdrs_f<0.05),]
data.svm <- data.frame(sel_ALLB1234, ALLB1234.factor)
mcr.svm.M<-matrix(NA, nrow=dim(sel_ALLB1234)[1], ncol=dim(sel_ALLB1234)[2])
for(i in 1:dim(sel_ALLB1234)[2]){
  data.tmp<-data.svm[-i,]
  p.t <-function(x) t.test(x~data.tmp$ALLB1234.factor)$p.value 
  p.value<-apply(data.tmp[,1:dim(sel_ALLB1234)[1]], 2, p.t)
  for(k in 1:dim(sel_ALLB1234)[1]){
    topknames<-names(data.tmp[,1:dim(sel_ALLB1234)[1]]) 
    topknames<-topknames[order(p.value)] 
    topknames<-topknames[1:k] 
    
    fml<-as.formula(paste("y~",paste(topknames,collapse="+")))
    svm.fit<-svm(fml, data=data.tmp, type = "C-classification", kernel = "linear") 
    svm.pred<-predict(svm.fit,data.svm[i,]) 
    mcr.svm.M[k,i]<- (svm.pred !=data.svm$ALLB1234.factor[i]) 
  }
}
```


##Question 5
###(a)
```{r warning=FALSE}
my.dat <- read.table(file = "DataPoisReg.txt", header = TRUE)
my.dat_x <- my.dat[,1]
my.dat_y <- my.dat[,2]
nloglik5 <- function(x) -sum(log2(dpois(my.dat_y, lambda = exp(x))))
theta5 <- optim(par = 1, nloglik5)$par

```

##(b)
```{r warning=FALSE}
lm(dpois(my.dat_y, lambda = theta5)~my.dat_x)
cat("The slope is -0.5296, not 2.")
```